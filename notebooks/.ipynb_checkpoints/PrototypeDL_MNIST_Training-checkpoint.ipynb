{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "788c6d72",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e6c51b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7668db94",
   "metadata": {},
   "source": [
    "# GPU/CUDA setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "375a0765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA enabled!\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    #device = torch.device('cuda')\n",
    "    print(\"CUDA enabled!\")\n",
    "device = 'cuda:0'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ','.join(f'{i}' for i in range(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afd4047",
   "metadata": {},
   "source": [
    "# Autoencoder Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c86a881",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Adopted from @author Oscar Li\n",
    "\n",
    "Source: https://github.com/OscarcarLi/PrototypeDL\n",
    "\"\"\"\n",
    "def makedirs(path):\n",
    "    '''\n",
    "    if path does not exist in the file system, create it\n",
    "    '''\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "def list_of_distances(X, Y):\n",
    "    '''\n",
    "    Given a list of vectors, X = [x_1, ..., x_n], and another list of vectors,\n",
    "    Y = [y_1, ... , y_m], we return a list of vectors\n",
    "            [[d(x_1, y_1), d(x_1, y_2), ... , d(x_1, y_m)],\n",
    "             ...\n",
    "             [d(x_n, y_1), d(x_n, y_2), ... , d(x_n, y_m)]],\n",
    "    where the distance metric used is the sqared euclidean distance.\n",
    "    The computation is achieved through a clever use of broadcasting.\n",
    "    '''\n",
    "    XX = torch.reshape(list_of_norms(X), shape=(-1, 1))\n",
    "\n",
    "    YY = torch.reshape(list_of_norms(Y), shape=(1, -1))\n",
    "    output = XX + YY - 2 * torch.matmul(X, torch.transpose(Y, 0, 1))\n",
    "    return output\n",
    "\n",
    "#xx = list_of_norms(x).view(-1, 1)\n",
    "#yy = list_of_norms(y).view(1, -1)\n",
    "#return xx + yy -2 * torch.matmul(x, torch.transpose(y, 0, 1))\n",
    "\n",
    "def list_of_norms(X):\n",
    "    '''\n",
    "    X is a list of vectors X = [x_1, ..., x_n], we return\n",
    "        [d(x_1, x_1), d(x_2, x_2), ... , d(x_n, x_n)], where the distance\n",
    "    function is the squared euclidean distance.\n",
    "    '''\n",
    "    return torch.sum(torch.pow(X, 2),dim=1)\n",
    "    #return torch.reduce_sum(torch.pow(X, 2), axis=1)\n",
    "\n",
    "def print_and_write(str, file):\n",
    "    '''\n",
    "    print str to the console and also write it to file\n",
    "    '''\n",
    "    print(str)\n",
    "    file.write(str + '\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363dd35c",
   "metadata": {},
   "source": [
    "# Network Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6b37de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, in_channels=1, n_maps=32, out_channels=10, n_layers=4):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        \n",
    "        el = []\n",
    "        el += [ConvLayer(in_channels, n_maps, stride=2, padding=1)]\n",
    "        for i in range(0, n_layers-2):\n",
    "            el += [ConvLayer(n_maps, n_maps, stride=2, padding=1)]   \n",
    "        el += [ConvLayer(n_maps, out_channels, stride=2, padding=1)]\n",
    "\n",
    "        self.encoder = nn.Sequential(*el)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.encoder(x)\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, in_channels=10, n_maps=32, out_channels=1, out_shapes=[], n_layers=4):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        dl = []\n",
    "        dl += [DeConvLayer(in_channels, n_maps, out_shape=out_shapes[-1], stride=2, padding=1, output_padding=1)]\n",
    "        for i in range(1, n_layers-1):\n",
    "            dl += [DeConvLayer(n_maps, n_maps, out_shape=out_shapes[-(i+1)], stride=2, padding=1, output_padding=1)]\n",
    "        dl += [DeConvLayer(n_maps, out_channels, out_shape=out_shapes[-n_layers], stride=2, padding=1, \n",
    "                           output_padding=1, activation=nn.Sigmoid)]\n",
    "\n",
    "        self.decoder = nn.Sequential(*dl)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decoder(x)\n",
    "\n",
    "class PrototypeLayer(nn.Module):\n",
    "    def __init__(self, in_channels=10, n_prototypes=15):\n",
    "        super(PrototypeLayer, self).__init__()\n",
    "\n",
    "        self.prototype_distances = torch.rand(n_prototypes, in_channels, requires_grad=True).to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return list_of_distances(x, self.prototype_distances)\n",
    "\n",
    "class ConvLayer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=2, padding=1, activation=nn.ReLU):\n",
    "        super(ConvLayer, self).__init__()\n",
    "        \n",
    "        self.conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3,\n",
    "                             stride=stride, padding=padding)\n",
    "        self.activation = activation()\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.in_dim = x.shape[-2:]\n",
    "        return self.activation(self.conv(x)) \n",
    "\n",
    "class DeConvLayer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, out_shape, stride=2, padding=1, output_padding=1, activation=nn.ReLU):\n",
    "        super(DeConvLayer, self).__init__()\n",
    "        self.out_shape = out_shape\n",
    "        self.dconv = nn.ConvTranspose2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, \n",
    "                                        stride=stride, padding=padding, output_padding=output_padding)\n",
    "        self.activation = activation()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out_convt = self.dconv(x)\n",
    "        if (out_convt.shape[-2:][0] != self.out_shape[0]) & (out_convt.shape[-2:][1] != self.out_shape[1]):\n",
    "            out_convt = out_convt[:,:,(out_convt.shape[-2:][0] - self.out_shape[0]):,\n",
    "                                 (out_convt.shape[-2:][1] - self.out_shape[1]):]\n",
    "        return self.activation(out_convt)\n",
    "\n",
    "class FullyConnectedLayer(nn.Module):\n",
    "    def __init__(self, in_features=15, out_features=10):\n",
    "        super(FullyConnectedLayer, self).__init__()\n",
    "\n",
    "        self.linear = nn.Linear(in_features=in_features, out_features=out_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "class Softmax(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Softmax, self).__init__()\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.softmax(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3812a10",
   "metadata": {},
   "source": [
    "# CAE Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "088839c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CAEModel(nn.Module):\n",
    "    def __init__(self, input_shape=(1, 1, 28,28), n_maps=32, n_prototypes=15, n_layers=4, n_classes=10):\n",
    "        super(CAEModel, self).__init__()\n",
    "\n",
    "        # add encoder layer\n",
    "        self.encoder = EncoderLayer(in_channels=input_shape[1], n_maps=n_maps, out_channels=n_classes, n_layers=n_layers)\n",
    "        \n",
    "        # add prototype layer\n",
    "        self.in_channels_prototype = self.encoder.forward(torch.randn(input_shape)).view(-1,1).shape[0]\n",
    "        self.prototype_layer = PrototypeLayer(in_channels=self.in_channels_prototype, n_prototypes=n_prototypes)\n",
    "\n",
    "        # add decoder layer\n",
    "        decoder_out_shapes = []\n",
    "        for layer in self.encoder.modules():\n",
    "            if isinstance(layer, ConvLayer):\n",
    "                decoder_out_shapes += [list(layer.in_dim)]\n",
    "        self.decoder = DecoderLayer(in_channels=n_classes, n_maps=n_maps, out_channels=input_shape[1], out_shapes=decoder_out_shapes)\n",
    "        \n",
    "        # output layer\n",
    "        # final fully connected layer\n",
    "        self.fc = FullyConnectedLayer(in_features=n_prototypes, out_features=n_classes)\n",
    "        self.feature_vectors = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoder_out = self.encoder(x)\n",
    "        self.feature_vectors = encoder_out\n",
    "        prototype_out = self.prototype_layer(encoder_out.view(-1,self.in_channels_prototype))\n",
    "        fc_out = self.fc(prototype_out)\n",
    "        return fc_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5c2b9f",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b0a0589",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Adopted from @author Oscar Li\n",
    "\n",
    "Source: https://github.com/OscarcarLi/PrototypeDL\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "from scipy.ndimage.interpolation import map_coordinates\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "\n",
    "def batch_elastic_transform(images, sigma, alpha, height, width, random_state=None):\n",
    "    '''\n",
    "    this code is borrowed from chsasank on GitHubGist\n",
    "    Elastic deformation of images as described in [Simard 2003].\n",
    "    \n",
    "    images: a two-dimensional numpy array; we can think of it as a list of flattened images\n",
    "    sigma: the real-valued variance of the gaussian kernel\n",
    "    alpha: a real-value that is multiplied onto the displacement fields\n",
    "    \n",
    "    returns: an elastically distorted image of the same shape\n",
    "    '''\n",
    "    assert len(images.shape) == 2\n",
    "    # the two lines below ensure we do not alter the array images\n",
    "    e_images = np.empty_like(images)\n",
    "    e_images[:] = images\n",
    "    \n",
    "    e_images = e_images.reshape(-1, height, width)\n",
    "    \n",
    "    if random_state is None:\n",
    "        random_state = np.random.RandomState(None)\n",
    "    x, y = np.mgrid[0:height, 0:width]\n",
    "    \n",
    "    for i in range(e_images.shape[0]):\n",
    "        \n",
    "        dx = gaussian_filter((random_state.rand(height, width) * 2 - 1), sigma, mode='constant') * alpha\n",
    "        dy = gaussian_filter((random_state.rand(height, width) * 2 - 1), sigma, mode='constant') * alpha\n",
    "        indices = x + dx, y + dy\n",
    "        e_images[i] = map_coordinates(e_images[i], indices, order=1)\n",
    "\n",
    "    return e_images.reshape(-1, height*width)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d870321d",
   "metadata": {},
   "source": [
    "# MINIST Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcc1c905",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "# function to load and return train and val multi-process iterator over the MNIST dataset.\n",
    "\n",
    "def get_train_val_loader(data_dir, batch_size, random_seed, augment=False, val_size=0.2, \n",
    "                         shuffle=True, show_sample=False, num_workers=0, pin_memory=True):\n",
    "\n",
    "    # load the dataset\n",
    "    train_dataset = datasets.MNIST(root=data_dir, train=True, \n",
    "                download=True, transform=transforms.ToTensor())\n",
    "    val_dataset = datasets.MNIST(root=data_dir, train=True, \n",
    "                download=True, transform=transforms.ToTensor())\n",
    "\n",
    "    num_train = len(train_dataset)\n",
    "    indices = list(range(num_train))\n",
    "    split = int(np.floor(val_size * num_train))\n",
    "\n",
    "    if shuffle == True:\n",
    "        np.random.seed(random_seed)\n",
    "        np.random.shuffle(indices)\n",
    "    train_idx, val_idx = indices[split:], indices[:split]\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    val_sampler = SubsetRandomSampler(val_idx)\n",
    "\n",
    "    # create data iterator\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler, \n",
    "                                               num_workers=num_workers, pin_memory=pin_memory)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, sampler=val_sampler, \n",
    "                                             num_workers=num_workers, pin_memory=pin_memory)\n",
    "    return (train_loader, val_loader)\n",
    "\n",
    "# function to load and return a multi-process test iterator over the MNIST dataset.\n",
    "def get_test_loader(data_dir, \n",
    "                    batch_size,\n",
    "                    shuffle=True,\n",
    "                    num_workers=0,\n",
    "                    pin_memory=True):\n",
    "\n",
    "    dataset = datasets.MNIST(root=data_dir, train=False, download=True, transform=transforms.ToTensor())\n",
    "    data_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, \n",
    "                                              num_workers=num_workers, pin_memory=pin_memory)\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78939055",
   "metadata": {},
   "source": [
    "# The directory to save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bc4f439",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder = os.path.join(os.getcwd(), \"saved_model\", \"mnist_model\", \"mnist_cae_1\")\n",
    "makedirs(model_folder)\n",
    "img_folder = os.path.join(model_folder, \"img\")\n",
    "makedirs(img_folder)\n",
    "model_filename = \"mnist_cae\"\n",
    "\n",
    "# console_log is the handle to a text file that records the console output\n",
    "log_folder=os.path.join(model_folder, \"log\")\n",
    "makedirs(log_folder)\n",
    "console_log = open(os.path.join(log_folder, \"console_log.txt\"), \"w+\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693074dc",
   "metadata": {},
   "source": [
    "# Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62f7fcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training parameters\n",
    "learning_rate = 0.002\n",
    "training_epochs = 100 #1500\n",
    "batch_size = 250              # the size of a minibatch\n",
    "test_display_step = 100       # how many epochs we do evaluate on the test set once\n",
    "save_step = 50                # how frequently do we save the model to disk\n",
    "\n",
    "# elastic deformation parameters\n",
    "sigma = 4\n",
    "alpha =20\n",
    "\n",
    "# lambda's are the ratios between the four error terms\n",
    "lambda_class = 20\n",
    "lambda_ae = 1\n",
    "lambda_1 = 1            # 1 and 2 here corresponds to the notation we used in the paper\n",
    "lambda_2 = 1\n",
    "\n",
    "# input data parameters\n",
    "input_height = 28         # MNIST data input shape\n",
    "input_width = input_height\n",
    "n_input_channel = 1       # the number of color channels; for MNIST is 1.\n",
    "input_size = input_height * input_width * n_input_channel   # the number of pixels in one input image\n",
    "input_shape = (1, n_input_channel, input_height, input_height) # input shape to pass in the model\n",
    "n_classes = 10\n",
    "\n",
    "# Network Parameters\n",
    "n_prototypes = 15         # the number of prototypes\n",
    "n_layers = 4\n",
    "n_maps = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb6c3b6",
   "metadata": {},
   "source": [
    "# Load MNIST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4300b1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#you may need to install the following packages in your python environment if it fails to donload data.\n",
    "#conda install -c conda-forge ipywidgets\n",
    "#jupyter nbextension enable --py widgetsnbextension\n",
    "# the following two for jupyter hosted environment\n",
    "#conda install -n base -c conda-forge widgetsnbextension\n",
    "#conda install -n <your_environment_name> -c conda-forge ipywidgets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f64d65e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 503: Service Unavailable\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5a593a663dd443994ff95174cdd65ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\train-images-idx3-ubyte.gz to data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66a8322df3bf4937b94351440a26c4a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 503: Service Unavailable\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae69e15b6eec483496363a3cbeb3b2c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59d3beb350b34ea4b1b9c519bf60b12f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to data\\MNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mrahman31\\Anaconda3\\envs\\torchenv\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "# data load and split parameters\n",
    "random_seed = 1\n",
    "n_workers = 0\n",
    "data_folder = 'data'\n",
    "\n",
    "# download MNIST data\n",
    "train_loader, val_loader = get_train_val_loader(data_folder, batch_size, random_seed, augment=False, val_size=0.2,\n",
    "                           shuffle=True, show_sample=False, num_workers=0, pin_memory=True)\n",
    "test_loader = get_test_loader(data_folder, batch_size, shuffle=True, num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640d6d6e",
   "metadata": {},
   "source": [
    "# Get the CAE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d02b43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CAEModel(input_shape=input_shape, n_maps=n_maps, n_prototypes=n_prototypes, \n",
    "                 n_layers=n_layers, n_classes=n_classes).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c068b18",
   "metadata": {},
   "source": [
    "# Optimizer setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4aa25a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38593928",
   "metadata": {},
   "source": [
    "# Train the model on MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "edaf2d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################################################\n",
      "Epoch: 0001\n",
      "batch: 192: 100%|████████████████████████████████████████████████████████████████████| 192/192 [00:24<00:00,  7.97it/s]\n",
      "\n",
      "\n",
      "training takes 24.11 seconds.\n",
      "training set errors:\n",
      "\tclassification error: 0.088640\n",
      "\tautoencoder error: 0.040643\n",
      "\terror_1: 0.583499\n",
      "\terror_2: 1.196367\n",
      "\ttotal error: 3.593300\n",
      "\taccuracy: 0.975208\n",
      "batch: 048: 100%|██████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 36.83it/s]\n",
      "\n",
      "\n",
      "validation set errors:\n",
      "\tclassification error: 0.036147\n",
      "\tautoencoder error: 0.045762\n",
      "\terror_1: 0.546004\n",
      "\terror_2: 1.255669\n",
      "\ttotal error: 2.570365\n",
      "\taccuracy: 0.984250\n",
      "################################################################################\n",
      "Epoch: 0002\n",
      "batch: 192: 100%|████████████████████████████████████████████████████████████████████| 192/192 [00:18<00:00, 10.45it/s]\n",
      "\n",
      "\n",
      "training takes 18.38 seconds.\n",
      "training set errors:\n",
      "\tclassification error: 0.120030\n",
      "\tautoencoder error: 0.039393\n",
      "\terror_1: 0.463751\n",
      "\terror_2: 1.275077\n",
      "\ttotal error: 4.178824\n",
      "\taccuracy: 0.975146\n",
      "batch: 048: 100%|██████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 45.71it/s]\n",
      "\n",
      "\n",
      "validation set errors:\n",
      "\tclassification error: 0.024571\n",
      "\tautoencoder error: 0.043150\n",
      "\terror_1: 0.480485\n",
      "\terror_2: 1.196095\n",
      "\ttotal error: 2.211156\n",
      "\taccuracy: 0.984167\n",
      "################################################################################\n",
      "Epoch: 0003\n",
      "batch: 192: 100%|████████████████████████████████████████████████████████████████████| 192/192 [00:18<00:00, 10.49it/s]\n",
      "\n",
      "\n",
      "training takes 18.31 seconds.\n",
      "training set errors:\n",
      "\tclassification error: 0.091361\n",
      "\tautoencoder error: 0.040200\n",
      "\terror_1: 0.577484\n",
      "\terror_2: 1.198693\n",
      "\ttotal error: 3.643594\n",
      "\taccuracy: 0.976854\n",
      "batch: 048: 100%|██████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 45.71it/s]\n",
      "\n",
      "\n",
      "validation set errors:\n",
      "\tclassification error: 0.113419\n",
      "\tautoencoder error: 0.043984\n",
      "\terror_1: 0.508568\n",
      "\terror_2: 1.158905\n",
      "\ttotal error: 3.979835\n",
      "\taccuracy: 0.984917\n",
      "################################################################################\n",
      "Epoch: 0004\n",
      "batch: 192: 100%|████████████████████████████████████████████████████████████████████| 192/192 [00:18<00:00, 10.64it/s]\n",
      "\n",
      "\n",
      "training takes 18.05 seconds.\n",
      "training set errors:\n",
      "\tclassification error: 0.057003\n",
      "\tautoencoder error: 0.038170\n",
      "\terror_1: 0.439560\n",
      "\terror_2: 1.191642\n",
      "\ttotal error: 2.809441\n",
      "\taccuracy: 0.977146\n",
      "batch: 048: 100%|██████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 42.98it/s]\n",
      "\n",
      "\n",
      "validation set errors:\n",
      "\tclassification error: 0.052845\n",
      "\tautoencoder error: 0.045629\n",
      "\terror_1: 0.498715\n",
      "\terror_2: 1.139872\n",
      "\ttotal error: 2.741118\n",
      "\taccuracy: 0.984333\n",
      "################################################################################\n",
      "Epoch: 0005\n",
      "batch: 192: 100%|████████████████████████████████████████████████████████████████████| 192/192 [00:18<00:00, 10.47it/s]\n",
      "\n",
      "\n",
      "training takes 18.34 seconds.\n",
      "training set errors:\n",
      "\tclassification error: 0.025139\n",
      "\tautoencoder error: 0.038086\n",
      "\terror_1: 0.709437\n",
      "\terror_2: 1.144268\n",
      "\ttotal error: 2.394564\n",
      "\taccuracy: 0.978083\n",
      "batch: 048: 100%|██████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 44.65it/s]\n",
      "\n",
      "\n",
      "validation set errors:\n",
      "\tclassification error: 0.023352\n",
      "\tautoencoder error: 0.045338\n",
      "\terror_1: 0.569605\n",
      "\terror_2: 1.131987\n",
      "\ttotal error: 2.213974\n",
      "\taccuracy: 0.984333\n",
      "################################################################################\n",
      "Epoch: 0006\n",
      "batch: 192: 100%|████████████████████████████████████████████████████████████████████| 192/192 [00:18<00:00, 10.44it/s]\n",
      "\n",
      "\n",
      "training takes 18.40 seconds.\n",
      "training set errors:\n",
      "\tclassification error: 0.088194\n",
      "\tautoencoder error: 0.039257\n",
      "\terror_1: 0.504090\n",
      "\terror_2: 1.267511\n",
      "\ttotal error: 3.574738\n",
      "\taccuracy: 0.977125\n",
      "batch: 048: 100%|██████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 44.53it/s]\n",
      "\n",
      "\n",
      "validation set errors:\n",
      "\tclassification error: 0.039308\n",
      "\tautoencoder error: 0.042534\n",
      "\terror_1: 0.568753\n",
      "\terror_2: 1.090953\n",
      "\ttotal error: 2.488407\n",
      "\taccuracy: 0.986250\n",
      "################################################################################\n",
      "Epoch: 0007\n",
      "batch: 192: 100%|████████████████████████████████████████████████████████████████████| 192/192 [00:18<00:00, 10.43it/s]\n",
      "\n",
      "\n",
      "training takes 18.41 seconds.\n",
      "training set errors:\n",
      "\tclassification error: 0.079153\n",
      "\tautoencoder error: 0.040961\n",
      "\terror_1: 0.568763\n",
      "\terror_2: 1.182008\n",
      "\ttotal error: 3.374799\n",
      "\taccuracy: 0.977625\n",
      "batch: 048: 100%|██████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 46.24it/s]\n",
      "\n",
      "\n",
      "validation set errors:\n",
      "\tclassification error: 0.061945\n",
      "\tautoencoder error: 0.044172\n",
      "\terror_1: 0.435579\n",
      "\terror_2: 1.087017\n",
      "\ttotal error: 2.805659\n",
      "\taccuracy: 0.985833\n",
      "################################################################################\n",
      "Epoch: 0008\n",
      "batch: 192: 100%|████████████████████████████████████████████████████████████████████| 192/192 [00:18<00:00, 10.36it/s]\n",
      "\n",
      "\n",
      "training takes 18.54 seconds.\n",
      "training set errors:\n",
      "\tclassification error: 0.125073\n",
      "\tautoencoder error: 0.039228\n",
      "\terror_1: 0.348550\n",
      "\terror_2: 1.158145\n",
      "\ttotal error: 4.047376\n",
      "\taccuracy: 0.978667\n",
      "batch: 048: 100%|██████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 45.41it/s]\n",
      "\n",
      "\n",
      "validation set errors:\n",
      "\tclassification error: 0.036399\n",
      "\tautoencoder error: 0.043749\n",
      "\terror_1: 0.433404\n",
      "\terror_2: 1.016830\n",
      "\ttotal error: 2.221962\n",
      "\taccuracy: 0.984917\n",
      "################################################################################\n",
      "Epoch: 0009\n",
      "batch: 192: 100%|████████████████████████████████████████████████████████████████████| 192/192 [00:17<00:00, 10.72it/s]\n",
      "\n",
      "\n",
      "training takes 17.92 seconds.\n",
      "training set errors:\n",
      "\tclassification error: 0.056252\n",
      "\tautoencoder error: 0.040055\n",
      "\terror_1: 0.519118\n",
      "\terror_2: 1.207921\n",
      "\ttotal error: 2.892124\n",
      "\taccuracy: 0.976521\n",
      "batch: 048: 100%|██████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 42.15it/s]\n",
      "\n",
      "\n",
      "validation set errors:\n",
      "\tclassification error: 0.075351\n",
      "\tautoencoder error: 0.045209\n",
      "\terror_1: 0.604731\n",
      "\terror_2: 1.125125\n",
      "\ttotal error: 3.282081\n",
      "\taccuracy: 0.982667\n",
      "################################################################################\n",
      "Epoch: 0010\n",
      "batch: 192: 100%|████████████████████████████████████████████████████████████████████| 192/192 [00:18<00:00, 10.49it/s]\n",
      "\n",
      "\n",
      "training takes 18.30 seconds.\n",
      "training set errors:\n",
      "\tclassification error: 0.077903\n",
      "\tautoencoder error: 0.037364\n",
      "\terror_1: 0.409311\n",
      "\terror_2: 1.134339\n",
      "\ttotal error: 3.139081\n",
      "\taccuracy: 0.978875\n",
      "batch: 048: 100%|██████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 46.06it/s]\n",
      "\n",
      "\n",
      "validation set errors:\n",
      "\tclassification error: 0.037392\n",
      "\tautoencoder error: 0.043100\n",
      "\terror_1: 0.517082\n",
      "\terror_2: 1.065984\n",
      "\ttotal error: 2.373998\n",
      "\taccuracy: 0.985667\n",
      "################################################################################\n",
      "Epoch: 0011\n",
      "batch: 192: 100%|████████████████████████████████████████████████████████████████████| 192/192 [00:18<00:00, 10.52it/s]\n",
      "\n",
      "\n",
      "training takes 18.25 seconds.\n",
      "training set errors:\n",
      "\tclassification error: 0.095406\n",
      "\tautoencoder error: 0.040973\n",
      "\terror_1: 0.537408\n",
      "\terror_2: 1.116627\n",
      "\ttotal error: 3.603122\n",
      "\taccuracy: 0.977771\n",
      "batch: 048: 100%|██████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 46.24it/s]\n",
      "\n",
      "\n",
      "validation set errors:\n",
      "\tclassification error: 0.080363\n",
      "\tautoencoder error: 0.044272\n",
      "\terror_1: 0.455872\n",
      "\terror_2: 1.177440\n",
      "\ttotal error: 3.284851\n",
      "\taccuracy: 0.983417\n",
      "################################################################################\n",
      "Epoch: 0012\n",
      "batch: 192: 100%|████████████████████████████████████████████████████████████████████| 192/192 [00:18<00:00, 10.54it/s]\n",
      "\n",
      "\n",
      "training takes 18.21 seconds.\n",
      "training set errors:\n",
      "\tclassification error: 0.103520\n",
      "\tautoencoder error: 0.038043\n",
      "\terror_1: 0.669423\n",
      "\terror_2: 1.107854\n",
      "\ttotal error: 3.885715\n",
      "\taccuracy: 0.978875\n",
      "batch: 048: 100%|██████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 45.45it/s]\n",
      "\n",
      "\n",
      "validation set errors:\n",
      "\tclassification error: 0.021752\n",
      "\tautoencoder error: 0.043760\n",
      "\terror_1: 0.404050\n",
      "\terror_2: 0.981264\n",
      "\ttotal error: 1.864120\n",
      "\taccuracy: 0.986167\n",
      "################################################################################\n",
      "Epoch: 0013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 192: 100%|████████████████████████████████████████████████████████████████████| 192/192 [00:18<00:00, 10.55it/s]\n",
      "\n",
      "\n",
      "training takes 18.20 seconds.\n",
      "training set errors:\n",
      "\tclassification error: 0.087981\n",
      "\tautoencoder error: 0.037832\n",
      "\terror_1: 0.494960\n",
      "\terror_2: 1.123593\n",
      "\ttotal error: 3.416002\n",
      "\taccuracy: 0.979771\n",
      "batch: 048: 100%|██████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 45.75it/s]\n",
      "\n",
      "\n",
      "validation set errors:\n",
      "\tclassification error: 0.056406\n",
      "\tautoencoder error: 0.044215\n",
      "\terror_1: 0.421494\n",
      "\terror_2: 1.045462\n",
      "\ttotal error: 2.639284\n",
      "\taccuracy: 0.986667\n",
      "################################################################################\n",
      "Epoch: 0014\n",
      "batch: 192: 100%|████████████████████████████████████████████████████████████████████| 192/192 [00:18<00:00, 10.51it/s]\n",
      "\n",
      "\n",
      "training takes 18.27 seconds.\n",
      "training set errors:\n",
      "\tclassification error: 0.047420\n",
      "\tautoencoder error: 0.037863\n",
      "\terror_1: 0.522824\n",
      "\terror_2: 1.145115\n",
      "\ttotal error: 2.654211\n",
      "\taccuracy: 0.978188\n",
      "batch: 048: 100%|██████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 45.62it/s]\n",
      "\n",
      "\n",
      "validation set errors:\n",
      "\tclassification error: 0.020403\n",
      "\tautoencoder error: 0.044031\n",
      "\terror_1: 0.381436\n",
      "\terror_2: 1.018140\n",
      "\ttotal error: 1.851662\n",
      "\taccuracy: 0.983333\n",
      "################################################################################\n",
      "Epoch: 0015\n",
      "batch: 192: 100%|████████████████████████████████████████████████████████████████████| 192/192 [00:18<00:00, 10.54it/s]\n",
      "\n",
      "\n",
      "training takes 18.22 seconds.\n",
      "training set errors:\n",
      "\tclassification error: 0.091538\n",
      "\tautoencoder error: 0.037842\n",
      "\terror_1: 0.393881\n",
      "\terror_2: 1.114012\n",
      "\ttotal error: 3.376489\n",
      "\taccuracy: 0.978688\n",
      "batch: 048: 100%|██████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 43.88it/s]\n",
      "\n",
      "\n",
      "validation set errors:\n",
      "\tclassification error: 0.076488\n",
      "\tautoencoder error: 0.043294\n",
      "\terror_1: 0.450943\n",
      "\terror_2: 1.071430\n",
      "\ttotal error: 3.095429\n",
      "\taccuracy: 0.985750\n",
      "################################################################################\n",
      "Epoch: 0016\n",
      "batch: 192: 100%|████████████████████████████████████████████████████████████████████| 192/192 [00:18<00:00, 10.53it/s]\n",
      "\n",
      "\n",
      "training takes 18.23 seconds.\n",
      "training set errors:\n",
      "\tclassification error: 0.084257\n",
      "\tautoencoder error: 0.037168\n",
      "\terror_1: 0.356878\n",
      "\terror_2: 1.043592\n",
      "\ttotal error: 3.122786\n",
      "\taccuracy: 0.980313\n",
      "batch: 048: 100%|██████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 46.24it/s]\n",
      "\n",
      "\n",
      "validation set errors:\n",
      "\tclassification error: 0.041083\n",
      "\tautoencoder error: 0.044416\n",
      "\terror_1: 0.373285\n",
      "\terror_2: 1.071593\n",
      "\ttotal error: 2.310959\n",
      "\taccuracy: 0.985500\n",
      "################################################################################\n",
      "Epoch: 0017\n",
      "batch: 192: 100%|████████████████████████████████████████████████████████████████████| 192/192 [00:17<00:00, 10.69it/s]\n",
      "\n",
      "\n",
      "training takes 17.96 seconds.\n",
      "training set errors:\n",
      "\tclassification error: 0.088693\n",
      "\tautoencoder error: 0.037645\n",
      "\terror_1: 0.440114\n",
      "\terror_2: 1.093602\n",
      "\ttotal error: 3.345225\n",
      "\taccuracy: 0.979730\n",
      "batch: 048: 100%|██████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 45.75it/s]\n",
      "\n",
      "\n",
      "validation set errors:\n",
      "\tclassification error: 0.031380\n",
      "\tautoencoder error: 0.043326\n",
      "\terror_1: 0.401722\n",
      "\terror_2: 1.042805\n",
      "\ttotal error: 2.115459\n",
      "\taccuracy: 0.985333\n",
      "################################################################################\n",
      "Epoch: 0018\n",
      "batch: 192: 100%|████████████████████████████████████████████████████████████████████| 192/192 [00:17<00:00, 10.78it/s]\n",
      "\n",
      "\n",
      "training takes 17.81 seconds.\n",
      "training set errors:\n",
      "\tclassification error: 0.065959\n",
      "\tautoencoder error: 0.038666\n",
      "\terror_1: 0.460965\n",
      "\terror_2: 1.121696\n",
      "\ttotal error: 2.940508\n",
      "\taccuracy: 0.978374\n",
      "batch: 048: 100%|██████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 44.04it/s]\n",
      "\n",
      "\n",
      "validation set errors:\n",
      "\tclassification error: 0.036973\n",
      "\tautoencoder error: 0.041393\n",
      "\terror_1: 0.370342\n",
      "\terror_2: 0.947734\n",
      "\ttotal error: 2.098929\n",
      "\taccuracy: 0.987417\n",
      "################################################################################\n",
      "Epoch: 0019\n",
      "batch: 192: 100%|████████████████████████████████████████████████████████████████████| 192/192 [00:18<00:00, 10.54it/s]\n",
      "\n",
      "\n",
      "training takes 18.22 seconds.\n",
      "training set errors:\n",
      "\tclassification error: 0.092742\n",
      "\tautoencoder error: 0.038943\n",
      "\terror_1: 0.427954\n",
      "\terror_2: 1.126188\n",
      "\ttotal error: 3.447926\n",
      "\taccuracy: 0.979542\n",
      "batch: 048: 100%|██████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 46.24it/s]\n",
      "\n",
      "\n",
      "validation set errors:\n",
      "\tclassification error: 0.065386\n",
      "\tautoencoder error: 0.041533\n",
      "\terror_1: 0.411111\n",
      "\terror_2: 0.966493\n",
      "\ttotal error: 2.726847\n",
      "\taccuracy: 0.983417\n",
      "################################################################################\n",
      "Epoch: 0020\n",
      "batch: 192: 100%|████████████████████████████████████████████████████████████████████| 192/192 [00:18<00:00, 10.52it/s]\n",
      "\n",
      "\n",
      "training takes 18.26 seconds.\n",
      "training set errors:\n",
      "\tclassification error: 0.081718\n",
      "\tautoencoder error: 0.040284\n",
      "\terror_1: 0.582544\n",
      "\terror_2: 1.064138\n",
      "\ttotal error: 3.321331\n",
      "\taccuracy: 0.980271\n",
      "batch: 048: 100%|██████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 46.28it/s]\n",
      "\n",
      "\n",
      "validation set errors:\n",
      "\tclassification error: 0.033028\n",
      "\tautoencoder error: 0.042815\n",
      "\terror_1: 0.385589\n",
      "\terror_2: 1.054374\n",
      "\ttotal error: 2.143330\n",
      "\taccuracy: 0.986333\n",
      "################################################################################\n",
      "Epoch: 0021\n",
      "batch: 192: 100%|████████████████████████████████████████████████████████████████████| 192/192 [00:18<00:00, 10.53it/s]\n",
      "\n",
      "\n",
      "training takes 18.24 seconds.\n",
      "training set errors:\n",
      "\tclassification error: 0.071129\n",
      "\tautoencoder error: 0.037594\n",
      "\terror_1: 0.493582\n",
      "\terror_2: 1.089219\n",
      "\ttotal error: 3.042974\n",
      "\taccuracy: 0.980396\n",
      "batch: 048: 100%|██████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 43.60it/s]\n",
      "\n",
      "\n",
      "validation set errors:\n",
      "\tclassification error: 0.037396\n",
      "\tautoencoder error: 0.043218\n",
      "\terror_1: 0.378428\n",
      "\terror_2: 0.947167\n",
      "\ttotal error: 2.116724\n",
      "\taccuracy: 0.987000\n",
      "################################################################################\n",
      "Epoch: 0022\n",
      "batch: 192: 100%|████████████████████████████████████████████████████████████████████| 192/192 [00:18<00:00, 10.53it/s]\n",
      "\n",
      "\n",
      "training takes 18.24 seconds.\n",
      "training set errors:\n",
      "\tclassification error: 0.045775\n",
      "\tautoencoder error: 0.036256\n",
      "\terror_1: 0.458197\n",
      "\terror_2: 1.152135\n",
      "\ttotal error: 2.562082\n",
      "\taccuracy: 0.980167\n",
      "batch: 048: 100%|██████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 44.94it/s]\n",
      "\n",
      "\n",
      "validation set errors:\n",
      "\tclassification error: 0.035488\n",
      "\tautoencoder error: 0.045583\n",
      "\terror_1: 0.481004\n",
      "\terror_2: 0.998691\n",
      "\ttotal error: 2.235030\n",
      "\taccuracy: 0.987333\n",
      "################################################################################\n",
      "Epoch: 0023\n",
      "batch: 192: 100%|████████████████████████████████████████████████████████████████████| 192/192 [00:18<00:00, 10.52it/s]\n",
      "\n",
      "\n",
      "training takes 18.25 seconds.\n",
      "training set errors:\n",
      "\tclassification error: 0.087088\n",
      "\tautoencoder error: 0.037551\n",
      "\terror_1: 0.454579\n",
      "\terror_2: 1.111517\n",
      "\ttotal error: 3.345409\n",
      "\taccuracy: 0.979604\n",
      "batch: 048: 100%|██████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 46.10it/s]\n",
      "\n",
      "\n",
      "validation set errors:\n",
      "\tclassification error: 0.087415\n",
      "\tautoencoder error: 0.042928\n",
      "\terror_1: 0.432664\n",
      "\terror_2: 0.970985\n",
      "\ttotal error: 3.194875\n",
      "\taccuracy: 0.986333\n",
      "################################################################################\n",
      "Epoch: 0024\n",
      "batch: 192: 100%|████████████████████████████████████████████████████████████████████| 192/192 [00:18<00:00, 10.55it/s]\n",
      "\n",
      "\n",
      "training takes 18.21 seconds.\n",
      "training set errors:\n",
      "\tclassification error: 0.022904\n",
      "\tautoencoder error: 0.037634\n",
      "\terror_1: 0.486195\n",
      "\terror_2: 1.052501\n",
      "\ttotal error: 2.034408\n",
      "\taccuracy: 0.981125\n",
      "batch: 048: 100%|██████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 45.24it/s]\n",
      "\n",
      "\n",
      "validation set errors:\n",
      "\tclassification error: 0.068553\n",
      "\tautoencoder error: 0.043811\n",
      "\terror_1: 0.357152\n",
      "\terror_2: 0.996044\n",
      "\ttotal error: 2.768076\n",
      "\taccuracy: 0.984583\n",
      "################################################################################\n",
      "Epoch: 0025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 192: 100%|████████████████████████████████████████████████████████████████████| 192/192 [00:18<00:00, 10.50it/s]\n",
      "\n",
      "\n",
      "training takes 18.29 seconds.\n",
      "training set errors:\n",
      "\tclassification error: 0.058086\n",
      "\tautoencoder error: 0.037830\n",
      "\terror_1: 0.365340\n",
      "\terror_2: 1.074652\n",
      "\ttotal error: 2.639534\n",
      "\taccuracy: 0.979729\n",
      "batch: 048: 100%|██████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 46.15it/s]\n",
      "\n",
      "\n",
      "validation set errors:\n",
      "\tclassification error: 0.019865\n",
      "\tautoencoder error: 0.044320\n",
      "\terror_1: 0.414105\n",
      "\terror_2: 1.032084\n",
      "\ttotal error: 1.887807\n",
      "\taccuracy: 0.985750\n",
      "################################################################################\n",
      "Epoch: 0026\n",
      "batch: 192: 100%|████████████████████████████████████████████████████████████████████| 192/192 [00:18<00:00, 10.49it/s]\n",
      "\n",
      "\n",
      "training takes 18.31 seconds.\n",
      "training set errors:\n",
      "\tclassification error: 0.079280\n",
      "\tautoencoder error: 0.036089\n",
      "\terror_1: 0.427147\n",
      "\terror_2: 1.012586\n",
      "\ttotal error: 3.061416\n",
      "\taccuracy: 0.980042\n",
      "batch: 048: 100%|██████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 46.15it/s]\n",
      "\n",
      "\n",
      "validation set errors:\n",
      "\tclassification error: 0.044448\n",
      "\tautoencoder error: 0.042875\n",
      "\terror_1: 0.354864\n",
      "\terror_2: 0.966048\n",
      "\ttotal error: 2.252750\n",
      "\taccuracy: 0.986333\n",
      "################################################################################\n",
      "Epoch: 0027\n",
      "batch: 192: 100%|████████████████████████████████████████████████████████████████████| 192/192 [00:18<00:00, 10.50it/s]\n",
      "\n",
      "\n",
      "training takes 18.28 seconds.\n",
      "training set errors:\n",
      "\tclassification error: 0.038984\n",
      "\tautoencoder error: 0.036716\n",
      "\terror_1: 0.529594\n",
      "\terror_2: 0.976633\n",
      "\ttotal error: 2.322632\n",
      "\taccuracy: 0.980271\n",
      "batch: 048: 100%|██████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 45.45it/s]\n",
      "\n",
      "\n",
      "validation set errors:\n",
      "\tclassification error: 0.103494\n",
      "\tautoencoder error: 0.042136\n",
      "\terror_1: 0.411749\n",
      "\terror_2: 0.970738\n",
      "\ttotal error: 3.494511\n",
      "\taccuracy: 0.986167\n",
      "################################################################################\n",
      "Epoch: 0028\n",
      "batch: 192: 100%|████████████████████████████████████████████████████████████████████| 192/192 [00:18<00:00, 10.52it/s]\n",
      "\n",
      "\n",
      "training takes 18.25 seconds.\n",
      "training set errors:\n",
      "\tclassification error: 0.058332\n",
      "\tautoencoder error: 0.036752\n",
      "\terror_1: 0.519105\n",
      "\terror_2: 0.984726\n",
      "\ttotal error: 2.707230\n",
      "\taccuracy: 0.979917\n",
      "batch: 048: 100%|██████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 46.10it/s]\n",
      "\n",
      "\n",
      "validation set errors:\n",
      "\tclassification error: 0.040198\n",
      "\tautoencoder error: 0.044056\n",
      "\terror_1: 0.365963\n",
      "\terror_2: 1.006633\n",
      "\ttotal error: 2.220618\n",
      "\taccuracy: 0.986917\n",
      "################################################################################\n",
      "Epoch: 0029\n",
      "batch: 192: 100%|████████████████████████████████████████████████████████████████████| 192/192 [00:18<00:00, 10.44it/s]\n",
      "\n",
      "\n",
      "training takes 18.39 seconds.\n",
      "training set errors:\n",
      "\tclassification error: 0.081329\n",
      "\tautoencoder error: 0.036423\n",
      "\terror_1: 0.497050\n",
      "\terror_2: 1.021518\n",
      "\ttotal error: 3.181581\n",
      "\taccuracy: 0.980687\n",
      "batch: 048: 100%|██████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 45.24it/s]\n",
      "\n",
      "\n",
      "validation set errors:\n",
      "\tclassification error: 0.031476\n",
      "\tautoencoder error: 0.043072\n",
      "\terror_1: 0.442674\n",
      "\terror_2: 0.975176\n",
      "\ttotal error: 2.090435\n",
      "\taccuracy: 0.986834\n",
      "################################################################################\n",
      "Epoch: 0030\n",
      "batch: 192: 100%|████████████████████████████████████████████████████████████████████| 192/192 [00:18<00:00, 10.49it/s]\n",
      "\n",
      "\n",
      "training takes 18.31 seconds.\n",
      "training set errors:\n",
      "\tclassification error: 0.061211\n",
      "\tautoencoder error: 0.040944\n",
      "\terror_1: 0.325818\n",
      "\terror_2: 1.127236\n",
      "\ttotal error: 2.718224\n",
      "\taccuracy: 0.980771\n",
      "batch: 048: 100%|██████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 46.19it/s]\n",
      "\n",
      "\n",
      "validation set errors:\n",
      "\tclassification error: 0.027040\n",
      "\tautoencoder error: 0.043533\n",
      "\terror_1: 0.327000\n",
      "\terror_2: 0.976347\n",
      "\ttotal error: 1.887678\n",
      "\taccuracy: 0.987500\n",
      "################################################################################\n",
      "Epoch: 0031\n",
      "batch: 192: 100%|████████████████████████████████████████████████████████████████████| 192/192 [00:19<00:00, 10.05it/s]\n",
      "\n",
      "\n",
      "training takes 19.10 seconds.\n",
      "training set errors:\n",
      "\tclassification error: 0.035806\n",
      "\tautoencoder error: 0.038925\n",
      "\terror_1: 0.510212\n",
      "\terror_2: 1.024946\n",
      "\ttotal error: 2.290202\n",
      "\taccuracy: 0.980083\n",
      "batch: 048: 100%|██████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 37.61it/s]\n",
      "\n",
      "\n",
      "validation set errors:\n",
      "\tclassification error: 0.027875\n",
      "\tautoencoder error: 0.044408\n",
      "\terror_1: 0.388159\n",
      "\terror_2: 0.922378\n",
      "\ttotal error: 1.912445\n",
      "\taccuracy: 0.986833\n",
      "################################################################################\n",
      "Epoch: 0032\n",
      "batch: 123:  64%|███████████████████████████████████████████▌                        | 123/192 [00:12<00:06,  9.97it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-282e8b04170a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[1;31m# apply elastic transform\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m             \u001b[0melastic_batch_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_elastic_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msigma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_height\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_width\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m             \u001b[0melastic_batch_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melastic_batch_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[0melastic_batch_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0melastic_batch_x\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-dd42fd8c21b4>\u001b[0m in \u001b[0;36mbatch_elastic_transform\u001b[1;34m(images, sigma, alpha, height, width, random_state)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0mdx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgaussian_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'constant'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m         \u001b[0mdy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgaussian_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'constant'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m         \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[0me_images\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmap_coordinates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me_images\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\scipy\\ndimage\\filters.py\u001b[0m in \u001b[0;36mgaussian_filter\u001b[1;34m(input, sigma, order, output, mode, cval, truncate)\u001b[0m\n\u001b[0;32m    340\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m             gaussian_filter1d(input, sigma, axis, order, output,\n\u001b[1;32m--> 342\u001b[1;33m                               mode, cval, truncate)\n\u001b[0m\u001b[0;32m    343\u001b[0m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\scipy\\ndimage\\filters.py\u001b[0m in \u001b[0;36mgaussian_filter1d\u001b[1;34m(input, sigma, axis, order, output, mode, cval, truncate)\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;31m# Since we are calling correlate, not convolve, revert the kernel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m     \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_gaussian_kernel1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msigma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 260\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcorrelate1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    261\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\scipy\\ndimage\\filters.py\u001b[0m in \u001b[0;36mcorrelate1d\u001b[1;34m(input, weights, axis, output, mode, cval, origin)\u001b[0m\n\u001b[0;32m    132\u001b[0m     \u001b[0mmode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_ni_support\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_mode_to_code\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     _nd_image.correlate1d(input, weights, axis, output, mode, cval,\n\u001b[1;32m--> 134\u001b[1;33m                           origin)\n\u001b[0m\u001b[0;32m    135\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "start_time= time.time()\n",
    "\n",
    "# train the model\n",
    "for epoch in range(0, training_epochs):\n",
    "    print_and_write(\"#\"*80, console_log)\n",
    "    print_and_write(\"Epoch: %04d\" % (epoch+1), console_log)\n",
    "    n_train_batch = len(train_loader)\n",
    "    n_val_batch = len(val_loader)\n",
    "    n_test_batch = len(test_loader)\n",
    "    start = time.time()\n",
    "\n",
    "    train_ce, train_ae, train_e1, train_e2, train_te, train_ac = 0.0, 0.0, 0.0, 0.0, 0.0, 0.0\n",
    "    \n",
    "    with tqdm(total=len(train_loader), file=sys.stdout) as pbar:\n",
    "        for i, batch in enumerate(train_loader):\n",
    "            batch_x = batch[0]\n",
    "            batch_y = batch[1]\n",
    "\n",
    "            # store original batch shape to put it back into this shape after transformation\n",
    "            batch_shape = batch_x.shape\n",
    "\n",
    "            # apply elastic transform\n",
    "            elastic_batch_x = batch_elastic_transform(batch_x.view(batch_size, -1), sigma=sigma, alpha=alpha, height=input_height, width=input_width)\n",
    "            elastic_batch_x = torch.reshape(torch.tensor(elastic_batch_x), batch_shape)\n",
    "            elastic_batch_x = elastic_batch_x.to(device)\n",
    "\n",
    "            batch_y = batch_y.to(device)\n",
    "\n",
    "            optimizer.zero_grad()        \n",
    "\n",
    "            pred_y = model.forward(elastic_batch_x)\n",
    "\n",
    "            # softmax crossentropy loss\n",
    "            loss_function = torch.nn.CrossEntropyLoss()\n",
    "            train_ce = loss_function(pred_y, batch_y)\n",
    "\n",
    "            prototype_distances = model.prototype_layer.prototype_distances\n",
    "            feature_vectors = model.feature_vectors\n",
    "\n",
    "            train_e1 = torch.mean(torch.min(list_of_distances(prototype_distances, feature_vectors.view(-1, model.in_channels_prototype)), dim=1)[0])\n",
    "            train_e2 = torch.mean(torch.min(list_of_distances(feature_vectors.view(-1, model.in_channels_prototype ), prototype_distances), dim=1)[0])\n",
    "\n",
    "            out_decoder = model.decoder(feature_vectors)\n",
    "            train_ae = torch.mean(list_of_norms(out_decoder-elastic_batch_x))\n",
    "\n",
    "            train_te = lambda_class * train_ce +\\\n",
    "                    lambda_1 * train_e1 +\\\n",
    "                    lambda_2 * train_e2 +\\\n",
    "                    lambda_ae * train_ae\n",
    "\n",
    "            train_te.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            # train accuracy\n",
    "            max_vals, max_indices = torch.max(pred_y,1)\n",
    "            n = max_indices.size(0)\n",
    "            train_ac += (max_indices == batch_y).sum(dtype=torch.float32)/n\n",
    "\n",
    "            pbar.set_description('batch: %03d' % (1 + i))\n",
    "            pbar.update(1)\n",
    "    \n",
    "    train_ac /= n_train_batch\n",
    "    print_and_write(\"training set errors:\"+\"\\tclassification error: {:.6f}\".format(train_ce)+\n",
    "                    \"\\tautoencoder error: {:.6f}\".format(train_ae)+\n",
    "                    \"\\terror_1: {:.6f}\".format(train_e1)+\n",
    "                    \"\\terror_2: {:.6f}\".format(train_e2)+\n",
    "                    \"\\ttotal error: {:.6f}\".format(train_te)+\n",
    "                    \"\\taccuracy: {:.6f}\".format(train_ac), console_log)\n",
    "    print_and_write('training takes {0:.2f} seconds.'.format((time.time() - start)), console_log)\n",
    "     \n",
    "    # validation set error terms evaluation\n",
    "    val_ce, val_ae, val_e1, val_e2, val_te, val_ac = 0.0, 0.0, 0.0, 0.0, 0.0, 0.0\n",
    "    \n",
    "    with tqdm(total=len(val_loader), file=sys.stdout) as pbar:\n",
    "        for i, batch in enumerate(val_loader):\n",
    "            batch_x = batch[0]\n",
    "            batch_y = batch[1]\n",
    "            batch_x = batch_x.to(device)\n",
    "            batch_y = batch_y.to(device)\n",
    "\n",
    "            pred_y = model.forward(batch_x)\n",
    "\n",
    "            loss_function = torch.nn.CrossEntropyLoss()\n",
    "            val_ce = loss_function(pred_y, batch_y)\n",
    "\n",
    "            prototype_distances = model.prototype_layer.prototype_distances\n",
    "            feature_vectors = model.feature_vectors\n",
    "\n",
    "            val_e1 = torch.mean(torch.min(list_of_distances(prototype_distances, feature_vectors.view(-1, model.in_channels_prototype)), dim=1)[0])\n",
    "            val_e2 = torch.mean(torch.min(list_of_distances(feature_vectors.view(-1, model.in_channels_prototype ), prototype_distances), dim=1)[0])\n",
    "\n",
    "            out_decoder = model.decoder(feature_vectors)\n",
    "            val_ae = torch.mean(list_of_norms(out_decoder-batch_x))\n",
    "\n",
    "            val_te = lambda_class * val_ce +\\\n",
    "                    lambda_1 * val_e1 +\\\n",
    "                    lambda_2 * val_e2 +\\\n",
    "                    lambda_ae * val_ae\n",
    "            # validation accuracy\n",
    "            max_vals, max_indices = torch.max(pred_y,1)\n",
    "            n = max_indices.size(0)\n",
    "            val_ac += (max_indices == batch_y).sum(dtype=torch.float32)/n\n",
    "\n",
    "            pbar.set_description('batch: %03d' % (1 + i))\n",
    "            pbar.update(1)\n",
    "           \n",
    "    val_ac /= n_val_batch\n",
    "    # after every epoch, check the error terms on the entire training set\n",
    "    print_and_write(\"validation set errors:\"+\"\\tclassification error: {:.6f}\".format(val_ce)+\n",
    "                    \"\\tautoencoder error: {:.6f}\".format(val_ae)+\n",
    "                    \"\\terror_1: {:.6f}\".format(val_e1)+\n",
    "                    \"\\terror_2: {:.6f}\".format(val_e2)+\n",
    "                    \"\\ttotal error: {:.6f}\".format(val_te)+\n",
    "                    \"\\taccuracy: {:.6f}\".format(val_ac), console_log)\n",
    "    \n",
    "    # test set accuracy evaluation\n",
    "    if (epoch+1) % test_display_step == 0 or epoch == training_epochs - 1:\n",
    "        test_ac = 0\n",
    "\n",
    "        for i, batch in enumerate(test_loader):\n",
    "            batch_x = batch[0]\n",
    "            batch_y = batch[1]\n",
    "            batch_x = batch_x.to(device)\n",
    "            batch_y = batch_y.to(device)\n",
    "\n",
    "            pred_y = model.forward(batch_x)\n",
    "\n",
    "            # test accuracy\n",
    "            max_vals, max_indices = torch.max(pred_y,1)\n",
    "            n = max_indices.size(0)\n",
    "            test_ac += (max_indices == batch_y).sum(dtype=torch.float32)/n\n",
    "\n",
    "        test_ac /= n_test_batch\n",
    "\n",
    "        print_and_write(\"test set:\", console_log)\n",
    "        print_and_write(\"\\taccuracy: {:.4f}\".format(test_ac), console_log)\n",
    "\n",
    "    if (epoch+1) % save_step == 0 or epoch == training_epochs - 1:\n",
    "        # save model states\n",
    "        model_state = {'model': model.state_dict(), 'optimizer': optimizer.state_dict(), 'epoch': epoch+1}\n",
    "        torch.save(model_state, os.path.join(model_folder, model_filename+'%05d.pth' % (epoch+1)))\n",
    "\n",
    "        # save outputs as images\n",
    "        # decode prototype vectors\n",
    "        prototype_imgs = model.decoder(prototype_distances.reshape((-1,10,2,2))).detach().cpu()\n",
    "\n",
    "        # visualize the prototype images\n",
    "        n_cols = 5\n",
    "        n_rows = n_prototypes // n_cols + 1 if n_prototypes % n_cols != 0 else n_prototypes // n_cols\n",
    "        g, b = plt.subplots(n_rows, n_cols, figsize=(n_cols, n_rows))\n",
    "        for i in range(n_rows):\n",
    "            for j in range(n_cols):\n",
    "                if i*n_cols + j < n_prototypes:\n",
    "                    b[i][j].imshow(prototype_imgs[i*n_cols + j].reshape(input_height, input_width),\n",
    "                                    cmap='gray',\n",
    "                                    interpolation='none')\n",
    "                    b[i][j].axis('off')\n",
    "                    \n",
    "        plt.savefig(os.path.join(img_folder, 'prototype_result-' + str(epoch+1) + '.png'),\n",
    "                    transparent=True, bbox_inches='tight', pad_inches=0)\n",
    "        plt.close()\n",
    "\n",
    "        # apply encoding and decoding over a small subset of the training set\n",
    "        batch_x = []\n",
    "        for batch in train_loader:\n",
    "            batch_x = batch[0].to(device)\n",
    "            break\n",
    "\n",
    "        examples_to_show = 10\n",
    "        \n",
    "        encoded = model.encoder.forward(batch_x[:examples_to_show])\n",
    "        decoded = model.decoder.forward(encoded)\n",
    "\n",
    "        decoded = decoded.detach().cpu()\n",
    "        imgs = batch_x.detach().cpu()\n",
    "\n",
    "        # compare original images to their reconstructions\n",
    "        f, a = plt.subplots(2, examples_to_show, figsize=(examples_to_show, 2))\n",
    "        for i in range(examples_to_show):\n",
    "            a[0][i].imshow(imgs[i].reshape(input_height, input_width),\n",
    "                            cmap='gray',\n",
    "                            interpolation='none')\n",
    "            a[0][i].axis('off')\n",
    "            a[1][i].imshow(decoded[i].reshape(input_height, input_width), \n",
    "                            cmap='gray',\n",
    "                            interpolation='none')\n",
    "            a[1][i].axis('off')\n",
    "            \n",
    "        plt.savefig(os.path.join(img_folder, 'decoding_result-' + str(epoch+1) + '.png'),\n",
    "                    transparent=True,\n",
    "                    bbox_inches='tight',\n",
    "                    pad_inches=0)\n",
    "        plt.close()\n",
    "        \n",
    "print_and_write('Total taken time {0:.2f} seconds.'.format((time.time() - start_time)), console_log)\n",
    "print_and_write(\"Optimization Finished!\", console_log)\n",
    "console_log.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f68a2095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed: 3: 100%|██████████████████████████████████████████████████████████████████████| 3/3 [00:03<00:00,  1.00s/it]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "\n",
    "values = range(3)\n",
    "with tqdm(total=len(values), file=sys.stdout) as pbar:\n",
    "    for i in values:\n",
    "        pbar.set_description('processed: %d' % (1 + i))\n",
    "        pbar.update(1)\n",
    "        sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a80845",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
